Выбор набора данных для задачи классификации и обоснование
Для задачи классификации был выбран датасет “Credit Card Fraud Detection”, содержащий данные о транзакциях по банковским картам.
Его выбор обусловлен следующими факторами:
1. Реальная практическая задача
Обнаружение мошеннических транзакций одна из самых значимых задач в сфере финансовой безопасности.
Банки и финансовые сервисы ежедневно анализируют миллионы операций, поэтому данная задача имеет огромную практическую ценность.
2. Наличие серьёзного дисбаланса классов
После анализа и визуализации данных я обнаружил:
мошеннических транзакций очень мало примерно 0.17%
данные сильно несбалансированы
Таким образом, задача классификации становится сложной и интересной, поскольку требуется:
бороться с дисбалансом,
выбирать правильные метрики,
применять корректную предобработку.


Выбор набора данных для задачи регрессии и обоснование

Для задачи регрессии был выбран датасет “Crop Yield Prediction”, содержащий данные об урожайности сельскохозяйственных культур.

1. Практическая важность
Прогнозирование урожайности  ключевая задача в:
агрономии, продовольственной безопасности, фермерском деле, экономическом планировании и логистике.
На основе таких моделей принимаются решения о количестве удобрений, объёме полива, распределении бюджета, планировании поставок и экспорта.
2. Наличие разнообразных факторов
Датасет содержит:
географический регион,
тип почвы,
тип культуры,
погодные условия,
температуру,
количество осадков,
длительность созревания,
использование удобрений и орошения.
Это создаёт многомерную, реалистичную задачу регрессионного моделирования.
Выбор метрик качества и обоснование их выбора


Метрики для задачи классификации (Credit Card Fraud Detection)


В данном датасете мошеннические транзакции составляют менее 0.2% от всех наблюдений.
Из-за этого класс мошенничества крайне редкий, что делает задачу сложной и в то же время очень показательной для анализа метрик.
После анализа распределения классов я увидел, что датасет является сильно несбалансированным.

Были выбраны следующие метрики:

1. Recall
Recall показывает, какую долю мошеннических транзакций модель действительно смогла обнаружить.
в банковской сфере лучше поднять лишнюю тревогу, чем пропустить мошенничество
пропущенная мошенническая транзакция это прямой финансовый ущерб
recall показывает способность модели находить редкие случаи
при сильном дисбалансе recall практически единственная метрика, отражающая безопасность системы.
2. F1-score
Поскольку высокая recall может привести к увеличению количества ложных срабатываний , используется F1-score, который балансирует precision recall
3. Accuracy
Accuracy показывает долю правильно классифицированных транзакций.
Однако в условиях дисбаланса accuracy растёт автоматически, даже если модель не обнаруживает ни одного мошенничества. Но мне все равно было интересно посмотреть эту метрику на моем датасете, а так как также измеряются recall и f1 то суждения о качестве не будут вестись только по ней

Метрики для задачи регрессии (crop yield prediction)

Я использовал:
1. RMSE
измеряется в тех же единицах, что и урожайность,
штрафует сильные ошибки,
легко интерпретируется.
2. R2
показывает, какую долю вариации урожайности модель объясняет,
значение близкое к 1 означает, что модель предсказывает почти идеально

Рассмотрим метрики

KNN

До оптимизаций

Классификация

Sklearn accuracy=0.9983, f1=0.9975, recall=0.030612244897959183 
Custom accuracy=0.9983, f1=0.9975, recall=0.030612244897959183

Регрессия

SkLearn RMSE=0.9842, R2=0.6640

Custom  RMSE=0.9842, R2=0.6640

После оптимизаций

Классификация

Sklearn accuracy=0.9995 f1=0.9995 recall=0.7857142857142857

Custom accuracy=0.9995 f1=0.9995 recall=0.7857142857142857

Регрессия

SkLearn RMSE=0.5727 R2=0.8862

Custom  RMSE=0.5727 R2=0.8862

Оценка пезультата

До оптимизаций: 

accuracy и f1 были практически идеальными 0.998, но recall катастрофически низким 0.03  KNN без настройки параметров плохо ловит редкие классы

После оптимизаций: 

recall сильно вырос до 0.785, сохранив при этом почти идеальные accuracy и f1 0.9995

Это огромный прогресс модель стала не только точной, но и существенно лучше распознаёт редкий класс

Регрессия 

До оптимизаций

RMSE 0.98, R2 0.66  среднее качество.

После оптимизаций:

RMSE снизился до 0.57, R2 вырос до 0.886.

Улучшение сильное и значимое. Для KNN регрессии это отличный результат
Вывод: KNN показал высокий результат, а после тюнинга метрики стали еще лучше

Линейные модели

До оптимизаций

Классификация

Sklearn accuracy=0.9980, f1=0.9980, recall=0.3333333333333333
Custom  accuracy=0.9985, f1=0.9978, recall=0.0

Регрессия

SkLearn RMSE=0.4922, R2=0.9160

Custom  RMSE=1.1651, R2=0.5293

После оптимизаций

Классификация

Sklearn accuracy=0.9885 f1=0.9929 recall=0.6666666666666666

Custom accuracy=0.9975 f1=0.9981 recall= 0.9825

Регрессия

SkLearn RMSE=0.4985 R2=0.9138

Custom  RMSE=0.6515 R2=0.8528

Оценка качества

Классификация

До оптимизаций
качество высокое, но recall был очень низкий, что означает полное игнорирование мошеннических транзакций плохой результат. Так и должно быть, ведь я еще никак не работал с данными

После оптимизаций

Sklearn снизил accuracy, но поднял recall до 0.66, что лучше сбалансировало модель

Custom сильно улучшил recall до 0.9825, сохранив высокий f1.

Очень сильный сдвиг. В линейные модели стали замечательно улавливать мошеннические транзакции

Регрессия

Sklearn: качество практически не изменилось R2 0.91, RMSE 0.49

Custom: улучшение заметное R2 вырос с 0.53 до 0.85.

Модель стала существенно лучше.

Вывод: оптимизации помогли обеим версиям, но особенно custom. Линейные модели после тюнинга стали показывать высокий результат.


Решающие деревья

До оптимизаций

Классификация

Sklearn accuracy=0.9990, f1=0.9988, recall=0.3333333333333333
   
Custom  accuracy=0.9995, f1=0.9995, recall=0.6666666666666666

Регрессия

SkLearn RMSE=0.6193, R2=0.8670

Custom  RMSE=0.6193, R2=0.8670

После оптимизаций

Классификация

Sklearn accuracy=0.9728 f1=0.9847 recall=0.8979591836734694

Custom accuracy=0.9755 f1=0.9860 recall=0.8775510204081632

Регрессия

SkLearn RMSE0.5317 R2=0.9020

Custom  RMSE=0.6193 R2=0.8670


Анализ результатов 

Классификация

До оптимизаций: качество очень высокое, но recall был низким.

После оптимизаций: recall подрос до 0.90, что значительно улучшает способность ловить редкий класс. Однако accuracy и f1 немного снизились.

Общий эффект: улучшение по recall, небольшое ухудшение общей точности  но модель стала более сбалансированной.

Регрессия

Sklearn: сильное улучшение RMSE с 0.62 до 0.53 R2 вырос до 0.9

Custom: без изменений модель не улучшилась.

Случайный лес

До оптимизаций

Классификация
Sklearn accuracy=0.9990, f1=0.9988, recall=0.3333333333333333

Custom accuracy=0.9995, f1=0.9995, recall=0.6666666666666666

Регрессия

SkLearn RMSE=0.5753, R2=0.8852

Custom  RMSE=0.5757, R2=0.8851

После оптимизаций

Классификация

Sklearn accuracy=0.9895 f1=0.9934 recall=0.8775510204081632

Custom accuracy=0.9755 f1=0.9860 recall=0.8775510204081632

Регрессия

SkLearn RMSE=0.5289 R2=0.9030

Custom  RMSE=0.5750 R2=0.8854

Оценка качества

Классификация

До оптимизаций: почти идеальные accuracy и f1, плохой recall.

После оптимизаций: sklearn получил recall 0.88 и сохранил высокий f1 хороши1 баланс.

Custom тоже улучшил recall, но общие метрики просели чуть сильнее.

Регрессия

Sklearn: улучшения RMSE 0.529, R2 0.903

Custom: практически остался на прежнем уровне.

Вывод: Random Forest стал одной из сильных моделей, показал очень высокое качество


Градиентный бустинг

До оптимизаций

Классификация

Sklearn accuracy=0.9992, f1=0.9992, recall=0.7448979591836735

Custom  accuracy=0.9987, f1=0.9988, recall=0.7653061224489796

Регрессия

SkLearn RMSE=1.1881, R2=0.5104 

Custom  RMSE=1.1881, R2=0.5104 

После оптимизаций

Классификация

Sklearn accuracy=0.9992 f1=0.9992 recall=0.7959183673469388

Custom accuracy=0.9985 f1=0.9986 recall=0.7040816326530612

Регрессия

SkLearn RMSE=0.5024 R2=0.9125

Custom  RMSE=0.8781 R2=0.7326

Оценка качкства

Классификация

До оптимизаций: уже был хорошим, высокий recall

После оптимизаций:

Sklearn улучшил recall до 0.796, сохранил идеальные accuracy и f1.
Custom, наоборот, стал немного хуже: recall чуть просел

Регрессия

Sklearn: гигантский скачок  R2 вырос с 0.51 до 0.91. Это отличный результат

Custom: улучшение есть, но слабое, осталось хуже sklearn.


Вывод

После всей серии экспериментов можно сказать, что оптимизация моделей дала действительно сильный эффект. Интересно наблюдать, как по-разному реагируют разные алгоритмы на подбор параметров и обработку данных одни совершенствуются плавно, другие сильно растут в качестве после правильных настроек
В классификации лучшим оказался KNN
Он не просто сохранил очень высокие значения accuracy и f1, но и сильно прибавил в recall и именно это делает его лучшим среди моих классификаторов. Модель стала намного более чувствительной к редкому классу, при этом не потеряв точности. Такой баланс встречается редко.
В регрессии лидирует градиентный бустинг
До оптимизаций он показывал средние результаты, но после настройки параметров сильно улучшился: RMSE сильно упал, R2 стал высоким. Такое поведение хорошо иллюстрирует работу бустинговых моделей при грамотной настройке они способны сильно улучшить качество
Работа получилась действительно интересной. До этого я никогда не погружался в эти алгоритмы так глубоко, отдельно хочу отметить, что эта работа была моим первым опытом работы с датасетом классификации с настолько большим дисбалансом классов, мне было интересно поэкспериментировать с этим.
В итоге можно сказать, что эксперимент не только помог выявить лучших моделей, но и дал очень ценный опыт: стало намного яснее, как важна правильная подготовка данных, подбор параметров и то, как сильно это влияет на качество.
